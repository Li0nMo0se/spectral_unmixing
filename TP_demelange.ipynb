{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP d'OCVX : démélange spectral par moindres carrés et régularisation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**/!\\** Avant de débuter le TP, vous devez avoir lu la petite introduction sur le démélange spectral. Les notations sont les mêmes que dans le document, et les termes spécifiques ne sont pas réintroduits ici."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif de ce TP est de vous faire manipuler la résolution d'un problème concret (en l'occurrence, le démélange spectral) par méthode des moindres carrés ordinaires, et de vous montrer ce qu'il est possible de faire lorsque le problème est mal posé via les méthodes de régularisation classiques.\n",
    "\n",
    "Pour le moment, nous n'avons pas le bagage théorique nécessaire à résolution complète du problème de démélange spectral, c'est à dire en intégrant les contraintes de positivité et de somme à 1 pour les abondances. Mais le démélange n'est ici qu'un prétexte, on prendra juste garde à ne pas chercher à interpréter les résultats obtenus pour les abondances en termes de proportions (sauf si vous arrivez à obtenir des abondances positives et sommant à 1 uniquement avec les méthodes abordées dans ce TP, auquel cas, on écrira directement une publication$\\dots$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les imports de base\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import scipy as sp\n",
    "from scipy import spatial\n",
    "import skimage\n",
    "from skimage import exposure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par importer les données (hsi $=$ *hyperspectral image*), et une vérité terrain (*gt $=$ ground truth*) normalement utilisée pour de la classification (mais elle va nous permettre de générer la matrice d'endmembers $\\mathbf{E}$ à moindres frais).\n",
    "\n",
    "Les données sont de suite normalisées entre 0 et 1 (correspondant à peu près à une conversion radiance $\\Rightarrow$ réflectance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsi = np.load('data/pavia.npy')\n",
    "gt = np.load('data/groundtruth.npy')\n",
    "hsi = hsi/hsi.max() # conversion de la réflectance en radiance\n",
    "Nrow,Ncol,Nbands = hsi.shape # sera utile plus tard pour les conversions tenseur 3D/matrice\n",
    "Npix = Nrow*Ncol\n",
    "print(hsi.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On vérifie tout de suite les dimensions de l'image : $610$ lignes, $340$ colonnes et $103$ bandes spectrales.\n",
    "\n",
    "\n",
    "Quelques infos : la scène a été acquise au dessus de l'université de Pavie, en Italie, par le capteur ROSIS 03 (*Reflective Optics System Imaging Spectrometer*). La résolution spatiale du capteur est de $2.6$ m (autrement dit, un pixel couvre une zone de $2.6 \\times 2.6$ m au sol). Les $103$ bandes spectrales s'étalent de $430$ nm à $860$ nm, avec une largeur de bande de $4.0$ nm.\n",
    "\n",
    "Pour visualiser cette image, il va tout d'abord falloir en extraire une image RGB, donc sélectionner un canal de rouge, un canal de vert et un canal de bleu parmi les $103$ bandes spectrales. Pour ce jeu de données, on utiliser en général $R = 47$, $G = 26$ et $B = 10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Par convention, les bandes RGB de cette image sont R=47, G=26 et B=10\n",
    "hsi_rgb = hsi[:,:,[47,26,10]]\n",
    "\n",
    "# Réétalonne la dynamique de l'histogramme de chaque bande RGB (étire l'histogramme comprit entre 1% et 99%)\n",
    "perc = 1\n",
    "plow, phigh = np.percentile(hsi_rgb, (perc, 100-perc))\n",
    "pimp_my_hsi_rgb = exposure.rescale_intensity(hsi_rgb, in_range=(plow, phigh))\n",
    "\n",
    "# Affiche tout ce bazar\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.subplot(131)\n",
    "plt.title('Image RGB non pimpée')\n",
    "plt.imshow(hsi_rgb)\n",
    "plt.subplot(132)\n",
    "plt.imshow(pimp_my_hsi_rgb)\n",
    "plt.title('Image RGB après pimpage de la dynamique')\n",
    "plt.subplot(133)\n",
    "ax = plt.gca()\n",
    "plt.title('Vérité terrain')\n",
    "imgt = ax.imshow(gt,cmap='jet')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "plt.colorbar(imgt, cax=cax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la vérité terrain ci-dessus, chacune des 9 classes présentent dans l'image est identifiée par un label allant de $1$ à $9$ (la classe $0£ étant, par convention, le fond de l'image). La correspondance des labels avec leur classe sémantique est donné ci-dessous\n",
    "\n",
    "| label | classe |\n",
    "|  ---  |   ---  | \n",
    "| 1 | Asphalte |\n",
    "| 2 | Champ/herbe |\n",
    "| 3 | Gravier |\n",
    "| 4 | Végétation |\n",
    "| 5 | Plaques de métal peintes |\n",
    "| 6 | Sol nu|\n",
    "| 7 | Bitume |\n",
    "| 8 | Briques autobloquantes |\n",
    "| 9 | Ombre |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plutôt que d'utiliser un algorithme d'induction aveugle d'endmembers ou une bibliothèque spectrale, on va se servir de la vérité terrain pour construire la matrice d'endmembers $\\mathbf{E}$.\n",
    "\n",
    "On va cependant exclure la classe \"ombre\", qui ne peut pas être considéré comme un constituant macroscopique pur. Pour les classes de $1$ à $8$, on va définir la signature spectral de l'endmember correspondant comme étant le médoïde de tous les pixels appartenant à la classe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1) Quelle est la différence principale entre le centroïde et le médoïde d'un ensemble de points ? Quel est le principal avantage du médoïde par rapport au centroïde ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme de calcul du médoïde d'un ensemble de points est donné ci-dessous (il n'est pas nécessaire d'essayer de le comprendre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vecteur médoïde xmed de X [Nsamples,Nfeatures]\n",
    "# (pompé sans aucune honte quelque part sur le net)\n",
    "def geometric_median(X, eps=1e-5):\n",
    "    y = np.mean(X, 0)\n",
    "\n",
    "    while True:\n",
    "        D = sp.spatial.distance.cdist(X, [y])\n",
    "        nonzeros = (D != 0)[:, 0]\n",
    "\n",
    "        Dinv = 1 / D[nonzeros]\n",
    "        Dinvs = np.sum(Dinv)\n",
    "        W = Dinv / Dinvs\n",
    "        T = np.sum(W * X[nonzeros], 0)\n",
    "\n",
    "        num_zeros = len(X) - np.sum(nonzeros)\n",
    "        if num_zeros == 0:\n",
    "            y1 = T\n",
    "        elif num_zeros == len(X):\n",
    "            return y\n",
    "        else:\n",
    "            R = (T - y) * Dinvs\n",
    "            r = np.linalg.norm(R)\n",
    "            rinv = 0 if r == 0 else num_zeros/r\n",
    "            y1 = max(0, 1-rinv)*T + min(1, rinv)*y\n",
    "\n",
    "        if sp.spatial.distance.euclidean(y, y1) < eps:\n",
    "            return y1\n",
    "\n",
    "        y = y1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut donc constituer la matrice d'endmembers $\\mathbf{E} \\in \\mathbb{R}^{N_{bands} \\times m}$, en récupérant le médoïde de chacune des $m=8$ premières classes de la vérité terrain. $N_{bands}$ étant évidemment le nombre de bandes dans l'image hyperspectrale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liste des noms des constituants macroscopiques\n",
    "endmembers = ['asphalt','meadows','gravel','tree','metal','soil','bitumen','brick']\n",
    "# m => nombre total d'endmembers considérés\n",
    "m = len(endmembers)\n",
    "# E => matrice Nbands x m\n",
    "E = np.zeros((Nbands,m))\n",
    "# vectorisation du cube 3D (Nrow x Ncol x Nbands) en matrice (Npix x Nbands)\n",
    "hsir = hsi.reshape(Npix,Nbands)\n",
    "# extraction du médoïde pour chaque classe\n",
    "for c in range(1,m+1): # indice des classes commençant à 1\n",
    "    class_idx = (gt==c).ravel() # indices vectorisé des pixels appartenant à la classe c\n",
    "    all_spectra = hsir[class_idx,:] # récupération des spectres correspondants (lignes de la matrice hsir)\n",
    "    E[:,c-1] = geometric_median(all_spectra) # calcul du médoïde et stockage dans E\n",
    "    \n",
    "# On affice les signatures spectrales des 8 endmembers\n",
    "plt.figure(figsize=(12,8))\n",
    "for m,em in enumerate(endmembers):\n",
    "    plt.plot(np.arange(1,104),E[:,m],label=em)\n",
    "plt.xlim((1,103))\n",
    "plt.xlabel('Bande')\n",
    "plt.ylabel('Réflectance')\n",
    "plt.legend(loc='best',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## II. Démélange par moindres carrés ordinaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "On attaque maintenant le vif du sujet. Étant donnés la matrice d'endmembers $\\mathbf{E} = [\\mathbf{e}_1,\\dots,\\mathbf{e}_m] \\in \\mathbb{R}^{N_{bands} \\times m}$ et le spectre $\\mathbf{x} \\in \\mathbb{R}^{N_{bands}}$ d'un pixel, on veut récupérer les abondances fractionnelles $\\boldsymbol \\phi = [\\phi_1,\\dots,\\phi_m]$ de $\\mathbf{x}$.\n",
    "\n",
    "D'après le LMM, $\\mathbf{x}$ s'écrit comme la combinaison linéaire des endmembers $\\mathbf{e}_i$ pondérés par leur abondance fractionnelle $\\phi_i$ correspondante (plus un bruit additif indépendant pour modéliser les imprefections du modèle) :\n",
    "$$ \\mathbf{x} = \\sum_{i=1}^m \\phi_i \\mathbf{e}_i + \\boldsymbol \\eta = \\mathbf{E} \\boldsymbol \\phi + \\eta$$\n",
    "\n",
    "L'inversion de ce modèle revient à calculer le vecteur $\\boldsymbol \\phi$ qui minimise la _residual sum of squares_ $RSS(\\boldsymbol \\phi) = \\displaystyle \\sum_{i=1}^{N_{bands}} \\big(x(i) - [\\mathbf{E}\\boldsymbol \\phi](i)\\big)^2 = \\|\\mathbf{x} -  \\mathbf{E}\\boldsymbol \\phi \\|_2^2$ :\n",
    "\n",
    "$$ \\boldsymbol \\phi = \\arg\\min_{\\boldsymbol \\phi \\in \\mathbb{R}^m} = \\|\\mathbf{x} -  \\mathbf{E}\\boldsymbol \\phi \\|_2^2 \\quad (1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**2.1) Retrouver analytiquement la solution du problème (1).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Il s'agira d'exprimer $\\boldsymbol \\phi$ en fonction de $\\mathbf{E}$ et $\\mathbf{x}$.\n",
    "\n",
    "Vous devez coder la solution analytique vous même dans un premier temps. Ce n'est que dans un second temps que vous pourrez vous rassurer (ou pas) en vérifiant que vous obtenez bien la même chose qu'un solveur de moindres carrés ordinaires.\n",
    "\n",
    "Démélangez dans un premier temps des spectres appartenant à l'une des 8 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2) En théorie, quelle devrait être la composition du vecteur d'abondances $\\boldsymbol \\phi$? Et qu'en est-il en pratique ? Comparez graphiquement le spectre initial $\\mathbf{x}$ avec sa reconstruction $\\hat{\\mathbf{x}} = \\mathbf{E}\\boldsymbol \\phi$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Il est coutûme de mesurer quantitativement la qualité de démélange de $\\mathbf{x}$ par l'erreur quadratique moyenne entre $\\mathbf{x}$ et sa reconstruction $\\mathbf{\\hat{x}} = \\sum_{i=1}^m \\phi_i \\mathbf{e}_i$ :\n",
    "\n",
    "$$\\epsilon(\\mathbf{x},\\mathbf{\\hat{x}}) = \\sqrt{\\frac{1}{N_{bands}} \\sum_{i=1}^{N_{bands}} (x(i) - \\hat{x}(i))^2} \\quad (2)$$\n",
    "\n",
    "**2.3) Implémentez la fonction d'erreur quadratique moyenne. Quel ordre de grandeur obtenez vous pour les spectres démélangées précédemment ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Démélanger pixel par pixel, c'est bien. Mais s'il était possible d'obtenir d'un coup les abondances fractionnelles de tous les pixels de l'image, ça serait vachement mieux. Et ça tombe bien, car c'est possible : il suffit d'utiliser la modélisation matricielle de l'image hyperspectrale $\\mathbf{X} \\in \\mathbb{R}^{N_{bands} \\times N_{pix}}$ et d'étendre le problème (1) sous la forme \n",
    "\n",
    "$$\\boldsymbol \\Phi = \\arg\\min_{\\Phi \\in \\mathbb{R}^{m\\times N_{pix}}} = \\|\\mathbf{X} -  \\mathbf{E}\\Phi \\|_2^2 \\quad (1)$$\n",
    "\n",
    "La solution $\\boldsymbol \\Phi \\in \\mathbb{R}^{m\\times N_{pix}}$ obtenue s'interprète donc comme une matrice d'abondances fractionnelles, où chaque colonne contient le vecteur d'abondance $\\boldsymbol \\phi$ du pixel correspondant. Cette matrice peut se réorganiser à moindres frais en un cube 3D $(N_{row} \\times N_{col} \\times m)$, où chaque canal peut se visualiser comme la carte d'abondances fractionelles de l'image entière pour l'endmember considéré."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**2.4) Adaptez votre implémentation de la question 2) pour obtenir la matrice d'abondance $\\boldsymbol \\Phi$ en un coup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5) Réorganisez la matrice précédente en un cube 3D et visualisez les différentes cartes d'abondances pour les 8 endmembers. Que remarquez vous/pouvez vous en conclure ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout comme l'équation (1) peut se reformuler pour obtenir une solution matricielle (la matrice $\\boldsymbol \\Phi$), il est possible d'obtenir d'un coup l'erreur quadratique moyenne de l'image entière $\\epsilon(\\mathbf{X},\\mathbf{\\hat{X}} = \\mathbf{E}\\boldsymbol \\Phi)$ (plutôt que de boucler sur tous les pixels).\n",
    "\n",
    "**2.6) Visualisez la carte d'erreur quadratique moyenne de l'image hyperspectral pour le démélange obtenu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On pourrait imaginer une stratégie de classification (naïve) suivante : chaque pixel est classifié selon son abondance fractionnelle majoritaire (puisqu'en théorie, plus l'abondance fractionelle est proche de $1$, plus le matériau correspondant est présent dans la signature spectrale du pixel en question). Même si le démélange obtenu précédemment avec les moindres carrés ordinaires devrait laisser à penser que cette stratégie est vouée à l'échec, on peut quand même y jeter un oeil.\n",
    "\n",
    "Elle pourrait avoir particulièrement du sens pour les pixels supposés \"purs\", c'est à dire tous les pixels de la vérité terrain dont le label est compris entre $1$ et $8$ (les pixels labelisés $0$ sont de classe inconnue du point de vue de la classification, et les pixels labelisés $9$ correspondant à de l'ombre (d'un autre matériau), ils ne sont pas purs non plus)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.7) Appliquez la stratégie de classification évoquée juste au dessus, à savoir que chaque pixel est classifié selon son abondance fractionnelle majoritaire, et visualisez la carte de classification obtenue. Que pouvez vous en conclure ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'évaluation qualitative précédente permet de donner des billes sur ce qui marche et ce qui ne marche pas à propos de la stratégie de classification appliquée. Mais cette évaluation qualitative doit être complétée par une évaluation quantitative plus rigoureuse, par le biais des métriques classiques de classification que vous connaissez.\n",
    "\n",
    "**2.8) Complétez votre analyse précédente par une évaluation quantitative : taux de bonne classification globale, matrice de confusion et taux de bonne classification par classe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Régularisation de Tikhonov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les techniques de régularisation sont très souvent utilisés pour la résolution de problèmes mal posés. Pour des problèmes linéaires sur-déterminés, c'est à dire du type $\\mathbf{A}\\mathbf{x} = \\mathbf{b}$, où la matrice $\\mathbf{A}$ possède plus de lignes que de colonnes - c'est notre cas ici - la régularisation va se matérialiser comme l'ajout d'un second terme $\\mathcal{R}(\\mathbf{x})$ au $RSS(\\mathbf{x}) = \\| \\mathbf{A}\\mathbf{x} - \\mathbf{b}\\|_2^2 $ :\n",
    "\n",
    "$$ RSS \\text{ avec régularisation : }  \\| \\mathbf{A}\\mathbf{x} - \\mathbf{b}\\|_2^2 + \\mathcal{R}(\\mathbf{x}), \\quad (3)$$\n",
    "\n",
    "de manière à ce que la solution de ce problème d'optimisation retrouver des propriétés souhaitables (de stabilité par exemple, c'est-à-dire qu'une légère perturbation de l'entrée n'entraine qu'une légère perturbation de la sortie, ce qui n'est pas le cas sans régularisation si $\\mathbf{A}$ est mal conditionnée.\n",
    "\n",
    "Le choix du terme de régularisation $\\mathcal{R}(\\mathbf{x})$ va bien sûr influer sur ces propriétés et sur la manière de résoudre le problème (3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le cas de la régularisation de Tikhonov, le terme de régularisation (aussi appelé _pénalité_) s'exprime comme $\\mathcal{R}(\\mathbf{x}) = \\lambda \\| \\boldsymbol \\Gamma \\mathbf{x}\\|_2^2$, où $\\boldsymbol \\Gamma$ (appelé matrice de Tikhonov) est déterminé en fonction du problème, et où $\\lambda$ permet de donner plus où moins de poids à la régularisation par rapport au RSS.\n",
    "\n",
    "Dans notre cas de démélange, $\\boldsymbol \\Gamma$ sera choisi comme la matrice identité, de manière à ce qu'on puisse réécrire le problème d'optimisation (en reprenant nos notations précédentes) : \n",
    "\n",
    "$$ \\arg\\min_{\\boldsymbol \\phi \\in \\mathbb{R}^m} = \\|\\mathbf{x} -  \\mathbf{E}\\boldsymbol \\phi \\|_2^2 + \\lambda \\|\\boldsymbol \\phi \\|_2^2\\quad (4)$$\n",
    "\n",
    "Ainsi, le terme de régularisation, en pénalisant les solutions ayant des composantes importantes (en valeur absolue), aura tendance à privilégier des solutions $\\boldsymbol \\phi$ dont la norme euclidienne est faible. La valeure de $\\lambda$ permettra de jouer sur le degré de régularisation (et donc la liberté qu'aura $\\boldsymbol \\phi$ d'avoir des entrées de magnitude élevée) : plus $\\lambda$ sera élevé, et plus la régularisation sera importante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sans surprise, le but de cette partie va être d'étudier l'influence de la régularisation de Tikhonov sur le problème d'estimation des abondances, et la comparaison avec la méthode des moindres carrés ordinaires. IL s'agira donc ici de reproduire ce qui a été fait dans la partie II, tout en intégrant l'étude de l'influence de $\\lambda$ sur la qualité du démélange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**3.1) Dérivez sur papier la solution analytique du problème (4)** (car oui, elle existe, et elle est pas tellement plus compliquée que la solution des moindres carrés ordinaires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2) Implémentez le démélange avec régularisation de Tikhonov pour quelques spectres de l'image. Que remarquez vous qualitativement (comparaison de la signature originelle $\\mathbf{x}$ avec la signature reconstruite) et quantitativement (valeur de l'erreur quadratique moyenne) par rapport aux solutions obtenues par moindres carrés ordinaires ? L'influence de $\\lambda$ est elle bien conforme à celle prédite par la théorie ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3) Vérifiez que vous retrouver bien la même solution que les solveurs classiques de ce problème de régularisation** (si vous voulez passer par une bibliothèque de *machine learning*, vous trouverez la solution du problème (4) sous son autre appelation, à savoir \"régression Ridge\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.4) Idem que pour les moindres carrés ordinaires, adaptez votre implémentation pour obtenir d'un coup la matrice d'abondances $\\boldsymbol \\Phi$ pour toute l'image. Affichez ces cartes d'abondances fractionnelles et la carte d'erreur quadratique moyenne de reconstruction pour l'image entière. Qu'en est-il de l'influence de $\\lambda$ ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.5) Ré-appliquez la stratégie de classification du point 2.7) précédent, et étudiez les résultats qualitativement et quantitativement (toujours en fonction de $\\lambda$). Quel est l'influence de la régularisation de Tikhonov sur les performances de classification ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Régularisation LASSO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "La régularisation LASSO (pour Least Absolute Shrinkage and Selection Operator), proposée en 1996 par Robert Tibshirani, est très similaire à celle de Tikhonov, sauf que la pénalité prend la forme d'une norme $\\mathcal{L}_1$ plutôt qu'une norme $\\mathcal{L}_2$. Plus particulièrement, le problème (4) précédent prend la forme de\n",
    "\n",
    "$$ \\arg\\min_{\\boldsymbol \\phi \\in \\mathbb{R}^m} = \\|\\mathbf{x} -  \\mathbf{E}\\boldsymbol \\phi \\|_2^2 + \\lambda \\|\\boldsymbol \\phi \\|_1\\quad (5)$$\n",
    "\n",
    "Cette régularisation, que l'on retrouve aussi sous le nom de _basis pursuit_ (une petite recherche bibliographique pourrait vous convaincre que les deux problèmes ne sont pas équivalents. Et pourtant, d'après la dualité Lagrangienne que vous verrez au S9, ils le sont).\n",
    "\n",
    "Malgré sa forte ressemblance avec la régularisation de Tikhonov, la résolution du problème $(5)$ se passe moins bien puisqu'il n'existe pas de solution analytique dans le cas général (il en existe une dans le cas particulier où $E^T E = Id$, ce qui n'est clairement pas le cas dans notre étude). On doit donc se tourner vers des méthodes itératives, dont le splus utilisées pour la résolution de $(5)$ sont les méthodes LARS (Least Angle Regressions), de gradient proximaux et de descente de gradient par coordonnées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Dans cette partie, vous allez implémenter la résolution de $(5)$ par descente de gradient par coordonnées. Bien qu'étant la plus abordable sur le plan théorique, cette méthode va vous amenez à toucher du doigt la notion de sous-différentiel, qui est au centre des algos de minimisation de fonctions convexes, mais non nécessairement différentiables.\n",
    "\n",
    "**Cette partie n'est volontairement pas guidée. La partie II a permis de mettre en place un cadre de résolution et d'analyse du problème des moindres carrés, et la partie III a permis d'ajouter l'aspect régularisation au problème. À vous de jouer :**\n",
    "\n",
    "**4.1) Cherchez** (vous trouverez une multitude de cours/slides/tutos plus ou moins clairs et didactiques sur le net)**, comprenez, et implémentez l'algorithme du LASSO par descente de gradient par coordonnées**\n",
    "\n",
    "**4.2) Menez à bien l'analyse qualitative et quantitative des performances du LASSO sur le problème de démélange spectral (aussi bien sur quelques spectres que sur l'image entière), ainsi que toutes les comparaisons qui vous paraîtront pertinentes avec la résolution par moindres carrés ordinaires et moindres carrés avec régularisation de Tikhonov**\n",
    "\n",
    "**4.3) Explicitez les conclusions que vous pouvez en tirer, et quelle méthode de résolution vous paraît la plus favorable étant données notamment les contraintes physiques de positivité et de somme à un sur les abondances (qui ne sont pas prises en compte ici).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
